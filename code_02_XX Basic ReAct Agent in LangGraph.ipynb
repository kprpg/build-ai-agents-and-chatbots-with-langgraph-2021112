{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a176bf0-e8e3-4598-a949-003b0fc6b8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tenacity==9.0.0\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: tenacity\n",
      "Successfully installed tenacity-9.0.0\n",
      "Collecting langchain==0.3.12\n",
      "  Downloading langchain-0.3.12-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain==0.3.12)\n",
      "  Downloading pyyaml-6.0.2.tar.gz (130 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.3.12)\n",
      "  Downloading sqlalchemy-2.0.42-py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.3.12)\n",
      "  Downloading aiohttp-3.12.15.tar.gz (7.8 MB)\n",
      "     ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 7.8/7.8 MB 48.8 MB/s  0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting langchain-core<0.4.0,>=0.3.25 (from langchain==0.3.12)\n",
      "  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain==0.3.12)\n",
      "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain==0.3.12)\n",
      "  Downloading langsmith-0.2.11-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<3,>=1.26.2 (from langchain==0.3.12)\n",
      "  Downloading numpy-2.3.2-cp313-cp313-win_arm64.whl.metadata (60 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain==0.3.12)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting requests<3,>=2 (from langchain==0.3.12)\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain==0.3.12) (9.0.0)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12)\n",
      "  Downloading frozenlist-1.7.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12)\n",
      "  Downloading multidict-6.6.3-cp313-cp313-win_arm64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12)\n",
      "  Downloading propcache-0.3.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.12)\n",
      "  Downloading yarl-1.20.1-py3-none-any.whl.metadata (73 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-core<0.4.0,>=0.3.25 (from langchain==0.3.12)\n",
      "  Downloading langchain_core-0.3.73-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.72-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.71-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.70-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.69-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.67-py3-none-any.whl.metadata (5.8 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.64-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.63-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.25->langchain==0.3.12)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.4.0,>=0.3.25->langchain==0.3.12)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core<0.4.0,>=0.3.25->langchain==0.3.12)\n",
      "  Using cached typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain==0.3.12)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain==0.3.12)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.3,>=0.1.17->langchain==0.3.12)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.17->langchain==0.3.12)\n",
      "  Downloading orjson-3.11.1-cp313-cp313-win_arm64.whl.metadata (43 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.17->langchain==0.3.12)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.12)\n",
      "  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.12)\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.12)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.12)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.12)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain==0.3.12)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain==0.3.12)\n",
      "  Using cached pydantic_core-2.33.2-cp313-cp313-win_arm64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain==0.3.12)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2->langchain==0.3.12)\n",
      "  Downloading charset_normalizer-3.4.3-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain==0.3.12)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.12)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading langchain-0.3.12-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 49.3 MB/s  0:00:00\n",
      "Downloading langchain_core-0.3.63-py3-none-any.whl (438 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.2.11-py3-none-any.whl (326 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading multidict-6.6.3-cp313-cp313-win_arm64.whl (43 kB)\n",
      "Downloading numpy-2.3.2-cp313-cp313-win_arm64.whl (10.2 MB)\n",
      "   ---------------------------------------- 0.0/10.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 10.2/10.2 MB 59.1 MB/s  0:00:00\n",
      "Downloading orjson-3.11.1-cp313-cp313-win_arm64.whl (126 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp313-cp313-win_arm64.whl (1.9 MB)\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-py3-none-any.whl (53 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading sqlalchemy-2.0.42-py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.9/1.9 MB 39.5 MB/s  0:00:00\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading yarl-1.20.1-py3-none-any.whl (46 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Downloading frozenlist-1.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading propcache-0.3.2-py3-none-any.whl (12 kB)\n",
      "Using cached typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Building wheels for collected packages: aiohttp, PyYAML\n",
      "  Building wheel for aiohttp (pyproject.toml): started\n",
      "  Building wheel for aiohttp (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for aiohttp: filename=aiohttp-3.12.15-cp313-cp313-win_arm64.whl size=417737 sha256=e0e5bb86a137f297e0f3bfb0f2adf6ac026ecb002b9cdb499816ad3fff0206f0\n",
      "  Stored in directory: c:\\users\\giris\\appdata\\local\\pip\\cache\\wheels\\57\\1a\\dc\\a4085b7df42b2ed8d30cbe55ac50a8ebae49547023b363b5b5\n",
      "  Building wheel for PyYAML (pyproject.toml): started\n",
      "  Building wheel for PyYAML (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for PyYAML: filename=pyyaml-6.0.2-cp313-cp313-win_arm64.whl size=45473 sha256=a032b431e531f449a2484de916607abe01ef2cf25b89bbcecd9e7a4d1682b2f8\n",
      "  Stored in directory: c:\\users\\giris\\appdata\\local\\pip\\cache\\wheels\\08\\66\\35\\56ce11fc5c36a272fe3ab08bc9c7ef9af2aeeb09d45db4e64e\n",
      "Successfully built aiohttp PyYAML\n",
      "Installing collected packages: urllib3, typing-extensions, sniffio, PyYAML, propcache, packaging, orjson, numpy, multidict, jsonpointer, idna, h11, frozenlist, charset_normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspection, SQLAlchemy, requests, pydantic-core, jsonpatch, httpcore, anyio, aiosignal, requests-toolbelt, pydantic, httpx, aiohttp, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "\n",
      "   ----------------------------------------  0/35 [urllib3]\n",
      "   ----------------------------------------  0/35 [urllib3]\n",
      "   ----------------------------------------  0/35 [urllib3]\n",
      "   ----------------------------------------  0/35 [urllib3]\n",
      "   --- ------------------------------------  3/35 [PyYAML]\n",
      "   --- ------------------------------------  3/35 [PyYAML]\n",
      "  Attempting uninstall: packaging\n",
      "   --- ------------------------------------  3/35 [PyYAML]\n",
      "    Found existing installation: packaging 25.0\n",
      "   --- ------------------------------------  3/35 [PyYAML]\n",
      "    Uninstalling packaging-25.0:\n",
      "   --- ------------------------------------  3/35 [PyYAML]\n",
      "      Successfully uninstalled packaging-25.0\n",
      "   --- ------------------------------------  3/35 [PyYAML]\n",
      "   ----- ----------------------------------  5/35 [packaging]\n",
      "   ------ ---------------------------------  6/35 [orjson]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   -------- -------------------------------  7/35 [numpy]\n",
      "   ----------- ---------------------------- 10/35 [idna]\n",
      "   ------------ --------------------------- 11/35 [h11]\n",
      "   ------------ --------------------------- 11/35 [h11]\n",
      "   -------------- ------------------------- 13/35 [charset_normalizer]\n",
      "   ---------------- ----------------------- 14/35 [certifi]\n",
      "   ----------------- ---------------------- 15/35 [attrs]\n",
      "   ------------------ --------------------- 16/35 [annotated-types]\n",
      "   -------------------- ------------------- 18/35 [yarl]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [SQLAlchemy]\n",
      "   ------------------------ --------------- 21/35 [requests]\n",
      "   ------------------------- -------------- 22/35 [pydantic-core]\n",
      "   --------------------------- ------------ 24/35 [httpcore]\n",
      "   --------------------------- ------------ 24/35 [httpcore]\n",
      "   --------------------------- ------------ 24/35 [httpcore]\n",
      "   ---------------------------- ----------- 25/35 [anyio]\n",
      "   ---------------------------- ----------- 25/35 [anyio]\n",
      "   ---------------------------- ----------- 25/35 [anyio]\n",
      "   ---------------------------- ----------- 25/35 [anyio]\n",
      "   ------------------------------ --------- 27/35 [requests-toolbelt]\n",
      "   ------------------------------ --------- 27/35 [requests-toolbelt]\n",
      "   -------------------------------- ------- 28/35 [pydantic]\n",
      "   -------------------------------- ------- 28/35 [pydantic]\n",
      "   -------------------------------- ------- 28/35 [pydantic]\n",
      "   -------------------------------- ------- 28/35 [pydantic]\n",
      "   -------------------------------- ------- 28/35 [pydantic]\n",
      "   -------------------------------- ------- 28/35 [pydantic]\n",
      "   -------------------------------- ------- 28/35 [pydantic]\n",
      "   -------------------------------- ------- 28/35 [pydantic]\n",
      "   -------------------------------- ------- 28/35 [pydantic]\n",
      "   -------------------------------- ------- 28/35 [pydantic]\n",
      "   -------------------------------- ------- 28/35 [pydantic]\n",
      "   --------------------------------- ------ 29/35 [httpx]\n",
      "   --------------------------------- ------ 29/35 [httpx]\n",
      "   --------------------------------- ------ 29/35 [httpx]\n",
      "   ---------------------------------- ----- 30/35 [aiohttp]\n",
      "   ---------------------------------- ----- 30/35 [aiohttp]\n",
      "   ---------------------------------- ----- 30/35 [aiohttp]\n",
      "   ---------------------------------- ----- 30/35 [aiohttp]\n",
      "   ----------------------------------- ---- 31/35 [langsmith]\n",
      "   ----------------------------------- ---- 31/35 [langsmith]\n",
      "   ----------------------------------- ---- 31/35 [langsmith]\n",
      "   ----------------------------------- ---- 31/35 [langsmith]\n",
      "   ----------------------------------- ---- 31/35 [langsmith]\n",
      "   ----------------------------------- ---- 31/35 [langsmith]\n",
      "   ------------------------------------ --- 32/35 [langchain-core]\n",
      "   ------------------------------------ --- 32/35 [langchain-core]\n",
      "   ------------------------------------ --- 32/35 [langchain-core]\n",
      "   ------------------------------------ --- 32/35 [langchain-core]\n",
      "   ------------------------------------ --- 32/35 [langchain-core]\n",
      "   ------------------------------------ --- 32/35 [langchain-core]\n",
      "   ------------------------------------ --- 32/35 [langchain-core]\n",
      "   ------------------------------------ --- 32/35 [langchain-core]\n",
      "   ------------------------------------ --- 32/35 [langchain-core]\n",
      "   ------------------------------------ --- 32/35 [langchain-core]\n",
      "   ------------------------------------ --- 32/35 [langchain-core]\n",
      "   ------------------------------------ --- 32/35 [langchain-core]\n",
      "   ------------------------------------ --- 32/35 [langchain-core]\n",
      "   ------------------------------------ --- 32/35 [langchain-core]\n",
      "   ------------------------------------- -- 33/35 [langchain-text-splitters]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   -------------------------------------- - 34/35 [langchain]\n",
      "   ---------------------------------------- 35/35 [langchain]\n",
      "\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.42 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 annotated-types-0.7.0 anyio-4.10.0 attrs-25.3.0 certifi-2025.8.3 charset_normalizer-3.4.3 frozenlist-1.7.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.12 langchain-core-0.3.63 langchain-text-splitters-0.3.8 langsmith-0.2.11 multidict-6.6.3 numpy-2.3.2 orjson-3.11.1 packaging-24.2 propcache-0.3.2 pydantic-2.11.7 pydantic-core-2.33.2 requests-2.32.4 requests-toolbelt-1.0.0 sniffio-1.3.1 typing-extensions-4.14.1 typing-inspection-0.4.1 urllib3-2.5.0 yarl-1.20.1\n",
      "Collecting langchain-openai==0.2.12\n",
      "  Downloading langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain-openai==0.2.12) (0.3.63)\n",
      "Collecting openai<2.0.0,>=1.55.3 (from langchain-openai==0.2.12)\n",
      "  Downloading openai-1.99.6-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.2.12)\n",
      "  Downloading tiktoken-0.11.0.tar.gz (37 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.126 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.2.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (4.14.1)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (3.11.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (1.0.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.16.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12)\n",
      "  Downloading jiter-0.10.0.tar.gz (162 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: sniffio in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.5.0)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai==0.2.12)\n",
      "  Downloading regex-2025.7.34-cp313-cp313-win_arm64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.4.6)\n",
      "Downloading langchain_openai-0.2.12-py3-none-any.whl (50 kB)\n",
      "Downloading openai-1.99.6-py3-none-any.whl (786 kB)\n",
      "   ---------------------------------------- 0.0/786.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 786.3/786.3 kB 16.4 MB/s  0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading regex-2025.7.34-cp313-cp313-win_arm64.whl (268 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Building wheels for collected packages: jiter, tiktoken\n",
      "  Building wheel for jiter (pyproject.toml): started\n",
      "  Building wheel for jiter (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for jiter: filename=jiter-0.10.0-cp313-cp313-win_arm64.whl size=187881 sha256=4452c0c7951bb07b9523af12019675e34c09ec47b0f64e542975b8af3cdef359\n",
      "  Stored in directory: c:\\users\\giris\\appdata\\local\\pip\\cache\\wheels\\e4\\2b\\95\\61970e487bee282aa7ee43f0c936b2d8a83b6d1d19143a79a6\n",
      "  Building wheel for tiktoken (pyproject.toml): started\n",
      "  Building wheel for tiktoken (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for tiktoken: filename=tiktoken-0.11.0-cp313-cp313-win_arm64.whl size=820194 sha256=e303f7dcc2f18103c9c15f65159e633234352413bb5a8c57c5c3d5e585419ca2\n",
      "  Stored in directory: c:\\users\\giris\\appdata\\local\\pip\\cache\\wheels\\3d\\fe\\74\\326b052b9b46ee1e74fc1e31046296488c7b32ad9f313fd566\n",
      "Successfully built jiter tiktoken\n",
      "Installing collected packages: tqdm, regex, jiter, distro, tiktoken, openai, langchain-openai\n",
      "\n",
      "   ---------------------------------------- 0/7 [tqdm]\n",
      "   ---------------------------------------- 0/7 [tqdm]\n",
      "   ----- ---------------------------------- 1/7 [regex]\n",
      "   ----------- ---------------------------- 2/7 [jiter]\n",
      "   ---------------------- ----------------- 4/7 [tiktoken]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------- ----------- 5/7 [openai]\n",
      "   ---------------------------------- ----- 6/7 [langchain-openai]\n",
      "   ---------------------------------- ----- 6/7 [langchain-openai]\n",
      "   ---------------------------------------- 7/7 [langchain-openai]\n",
      "\n",
      "Successfully installed distro-1.9.0 jiter-0.10.0 langchain-openai-0.2.12 openai-1.99.6 regex-2025.7.34 tiktoken-0.11.0 tqdm-4.67.1\n",
      "Collecting langchain_community==0.3.12\n",
      "  Downloading langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain_community==0.3.12) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain_community==0.3.12) (2.0.42)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain_community==0.3.12) (3.12.15)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community==0.3.12)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community==0.3.12)\n",
      "  Using cached httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.12 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain_community==0.3.12) (0.3.12)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.25 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain_community==0.3.12) (0.3.63)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain_community==0.3.12) (0.2.11)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain_community==0.3.12) (2.3.2)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community==0.3.12)\n",
      "  Using cached pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain_community==0.3.12) (2.32.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain_community==0.3.12) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.12) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.12) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.12) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.12) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.12) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.12) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.12) (1.20.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.12)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.12)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain<0.4.0,>=0.3.12->langchain_community==0.3.12) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain<0.4.0,>=0.3.12->langchain_community==0.3.12) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.25->langchain_community==0.3.12) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.25->langchain_community==0.3.12) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.25->langchain_community==0.3.12) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain_community==0.3.12) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain_community==0.3.12) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain_community==0.3.12) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain_community==0.3.12) (1.0.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community==0.3.12) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community==0.3.12) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community==0.3.12) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community==0.3.12) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community==0.3.12) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.12->langchain_community==0.3.12) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.12->langchain_community==0.3.12) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.12->langchain_community==0.3.12) (0.4.1)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community==0.3.12)\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community==0.3.12) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community==0.3.12) (2.5.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.12)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community==0.3.12) (1.3.1)\n",
      "Downloading langchain_community-0.3.12-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 36.3 MB/s  0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
      "\n",
      "   ---------------------------------------- 0/8 [python-dotenv]\n",
      "   ---------- ----------------------------- 2/8 [marshmallow]\n",
      "   -------------------- ------------------- 4/8 [typing-inspect]\n",
      "   ------------------------- -------------- 5/8 [pydantic-settings]\n",
      "   ------------------------------ --------- 6/8 [dataclasses-json]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ----------------------------------- ---- 7/8 [langchain_community]\n",
      "   ---------------------------------------- 8/8 [langchain_community]\n",
      "\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain_community-0.3.12 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n",
      "Collecting langgraph==0.2.59\n",
      "  Downloading langgraph-0.2.59-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langgraph==0.2.59) (0.3.63)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.4 (from langgraph==0.2.59)\n",
      "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph==0.2.59)\n",
      "  Downloading langgraph_sdk-0.1.74-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.126 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.59) (0.2.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.59) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.59) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.59) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.59) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.59) (4.14.1)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.59) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.59) (3.0.0)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph==0.2.59)\n",
      "  Downloading ormsgpack-1.10.0.tar.gz (58 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.59) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.59) (3.11.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.59) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.59) (1.0.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.59) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.59) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.59) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.59) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.59) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.59) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.59) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from pydantic>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.59) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.59) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.59) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.59) (1.3.1)\n",
      "Downloading langgraph-0.2.59-py3-none-any.whl (135 kB)\n",
      "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
      "Downloading langgraph_sdk-0.1.74-py3-none-any.whl (50 kB)\n",
      "Building wheels for collected packages: ormsgpack\n",
      "  Building wheel for ormsgpack (pyproject.toml): started\n",
      "  Building wheel for ormsgpack (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for ormsgpack: filename=ormsgpack-1.10.0-cp313-cp313-win_arm64.whl size=105736 sha256=db1892f034ccea487a437eba62bd800a1d65eb679248cd3344c9345ac09081d9\n",
      "  Stored in directory: c:\\users\\giris\\appdata\\local\\pip\\cache\\wheels\\fc\\4a\\43\\5c04ef2d74dcd32b2d9bb5fa09a47e780ff58979cfbdd89e85\n",
      "Successfully built ormsgpack\n",
      "Installing collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [langgraph-sdk]\n",
      "   -------------------- ------------------- 2/4 [langgraph-checkpoint]\n",
      "   ------------------------------ --------- 3/4 [langgraph]\n",
      "   ------------------------------ --------- 3/4 [langgraph]\n",
      "   ------------------------------ --------- 3/4 [langgraph]\n",
      "   ------------------------------ --------- 3/4 [langgraph]\n",
      "   ------------------------------ --------- 3/4 [langgraph]\n",
      "   ---------------------------------------- 4/4 [langgraph]\n",
      "\n",
      "Successfully installed langgraph-0.2.59 langgraph-checkpoint-2.1.1 langgraph-sdk-0.1.74 ormsgpack-1.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pysqlite3-binary==0.5.4 (from versions: none)\n",
      "ERROR: No matching distribution found for pysqlite3-binary==0.5.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_chroma==0.1.4\n",
      "  Downloading langchain_chroma-0.1.4-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 (from langchain_chroma==0.1.4)\n",
      "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting fastapi<1,>=0.95.2 (from langchain_chroma==0.1.4)\n",
      "  Downloading fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.1.40 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from langchain_chroma==0.1.4) (0.3.63)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from langchain_chroma==0.1.4)\n",
      "  Downloading numpy-1.26.4.tar.gz (15.8 MB)\n",
      "     ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "     ---------------------------------- ---- 13.9/15.8 MB 74.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 15.8/15.8 MB 68.9 MB/s  0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting build>=1.0.3 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma==0.1.4)\n",
      "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma==0.1.4) (2.11.7)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma==0.1.4)\n",
      "  Downloading chroma_hnswlib-0.7.6.tar.gz (32 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma==0.1.4)\n",
      "  Using cached uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma==0.1.4)\n",
      "  Downloading posthog-6.5.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma==0.1.4) (4.14.1)\n",
      "INFO: pip is looking at multiple versions of chromadb to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 (from langchain_chroma==0.1.4)\n",
      "  Downloading chromadb-0.5.21-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading chromadb-0.5.20-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading chromadb-0.5.18-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading chromadb-0.5.17-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading chromadb-0.5.16-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading chromadb-0.5.15-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading chromadb-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "INFO: pip is still looking at multiple versions of chromadb to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading chromadb-0.5.12-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading chromadb-0.5.11-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading chromadb-0.5.10-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading chromadb-0.5.9-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading chromadb-0.5.7-py3-none-any.whl.metadata (6.8 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading chromadb-0.5.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma==0.1.4) (2.32.4)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma==0.1.4)\n",
      "  Downloading chroma-hnswlib-0.7.3.tar.gz (31 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 (from langchain_chroma==0.1.4)\n",
      "  Downloading chromadb-0.5.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading chromadb-0.5.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading chromadb-0.5.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Downloading chromadb-0.4.23-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Downloading chromadb-0.4.22-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Downloading chromadb-0.4.21-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Downloading chromadb-0.4.20-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Downloading chromadb-0.4.19-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Downloading chromadb-0.4.18-py3-none-any.whl.metadata (7.4 kB)\n",
      "  Downloading chromadb-0.4.17-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Downloading chromadb-0.4.16-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Downloading chromadb-0.4.15-py3-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading chromadb-0.4.14-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading chromadb-0.4.13-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading chromadb-0.4.12-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting pydantic<2.0,>=1.9 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma==0.1.4)\n",
      "  Downloading pydantic-1.10.22-py3-none-any.whl.metadata (154 kB)\n",
      "Collecting fastapi<1,>=0.95.2 (from langchain_chroma==0.1.4)\n",
      "  Downloading fastapi-0.99.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 (from langchain_chroma==0.1.4)\n",
      "  Downloading chromadb-0.4.11-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading chromadb-0.4.10-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading chromadb-0.4.9-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting chroma-hnswlib==0.7.2 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma==0.1.4)\n",
      "  Downloading chroma-hnswlib-0.7.2.tar.gz (31 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 (from langchain_chroma==0.1.4)\n",
      "  Downloading chromadb-0.4.8-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Downloading chromadb-0.4.7-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Downloading chromadb-0.4.6-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading chromadb-0.4.5-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading chromadb-0.4.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading chromadb-0.4.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pandas>=1.3 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma==0.1.4)\n",
      "  Downloading pandas-2.3.1.tar.gz (4.5 MB)\n",
      "     ---------------------------------------- 0.0/4.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 4.5/4.5 MB 48.8 MB/s  0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting chroma-hnswlib==0.7.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma==0.1.4)\n",
      "  Downloading chroma-hnswlib-0.7.1.tar.gz (30 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 (from langchain_chroma==0.1.4)\n",
      "  Downloading chromadb-0.4.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Downloading chromadb-0.4.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Downloading chromadb-0.4.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "\n",
      "The conflict is caused by:\n",
      "    chromadb 0.5.23 depends on onnxruntime>=1.14.1\n",
      "    chromadb 0.5.21 depends on onnxruntime>=1.14.1\n",
      "    chromadb 0.5.20 depends on onnxruntime>=1.14.1\n",
      "    chromadb 0.5.18 depends on onnxruntime>=1.14.1\n",
      "    chromadb 0.5.17 depends on onnxruntime>=1.14.1\n",
      "    chromadb 0.5.16 depends on onnxruntime>=1.14.1\n",
      "    chromadb 0.5.15 depends on onnxruntime>=1.14.1\n",
      "    chromadb 0.5.13 depends on onnxruntime>=1.14.1\n",
      "    chromadb 0.5.12 depends on onnxruntime>=1.14.1\n",
      "    chromadb 0.5.11 depends on onnxruntime>=1.14.1\n",
      "    chromadb 0.5.10 depends on onnxruntime>=1.14.1\n",
      "    chromadb 0.5.9 depends on onnxruntime>=1.14.1\n",
      "    chromadb 0.5.7 depends on onnxruntime>=1.14.1\n",
      "    chromadb 0.5.3 depends on onnxruntime>=1.14.1\n",
      "    chromadb 0.5.2 depends on onnxruntime>=1.14.1\n",
      "    chromadb 0.5.1 depends on onnxruntime>=1.14.1\n",
      "    chromadb 0.5.0 depends on onnxruntime>=1.14.1\n",
      "    chromadb 0.4.24 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.23 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.22 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.21 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.20 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.19 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.18 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.17 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.16 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.15 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.14 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.13 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.12 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.11 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.10 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.9 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.8 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.7 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.6 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.5 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.4 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.3 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.2 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.1 depends on pulsar-client>=3.1.0\n",
      "    chromadb 0.4.0 depends on pulsar-client>=3.1.0\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install langchain_chroma because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==2.2.3\n",
      "  Downloading pandas-2.2.3.tar.gz (4.4 MB)\n",
      "     ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 4.4/4.4 MB 38.0 MB/s  0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from pandas==2.2.3) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from pandas==2.2.3) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas==2.2.3)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas==2.2.3)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas==2.2.3) (1.17.0)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Building wheels for collected packages: pandas\n",
      "  Building wheel for pandas (pyproject.toml): started\n",
      "  Building wheel for pandas (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pandas: filename=pandas-2.2.3-cp313-cp313-win_arm64.whl size=37865045 sha256=6c5c12b21607a71349842fa27f54d7bce70f3c529e615b51e16d210b03a37d65\n",
      "  Stored in directory: c:\\users\\giris\\appdata\\local\\pip\\cache\\wheels\\98\\55\\bb\\28ac1d8a94fa3cbd670d129098f5452e7943c9acffe133b4f8\n",
      "Successfully built pandas\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   ---------------------------------------- 3/3 [pandas]\n",
      "\n",
      "Successfully installed pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "Collecting pypdf==5.1.0\n",
      "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-5.1.0\n",
      "Collecting nbformat==5.10.4\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat==5.10.4)\n",
      "  Downloading fastjsonschema-2.21.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting jsonschema>=2.6 (from nbformat==5.10.4)\n",
      "  Using cached jsonschema-4.25.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from nbformat==5.10.4) (5.8.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from nbformat==5.10.4) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat==5.10.4) (25.3.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=2.6->nbformat==5.10.4)\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=2.6->nbformat==5.10.4)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=2.6->nbformat==5.10.4)\n",
      "  Downloading rpds_py-0.27.0-cp313-cp313-win_arm64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat==5.10.4) (4.3.8)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\giris\\source\\repos\\build-ai-agents-and-chatbots-with-langgraph-2021112\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat==5.10.4) (311)\n",
      "Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Downloading fastjsonschema-2.21.1-py3-none-any.whl (23 kB)\n",
      "Using cached jsonschema-4.25.0-py3-none-any.whl (89 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.27.0-cp313-cp313-win_arm64.whl (222 kB)\n",
      "Installing collected packages: fastjsonschema, rpds-py, referencing, jsonschema-specifications, jsonschema, nbformat\n",
      "\n",
      "   ---------------------------------------- 0/6 [fastjsonschema]\n",
      "   ------------- -------------------------- 2/6 [referencing]\n",
      "   -------------------------- ------------- 4/6 [jsonschema]\n",
      "   -------------------------- ------------- 4/6 [jsonschema]\n",
      "   -------------------------- ------------- 4/6 [jsonschema]\n",
      "   --------------------------------- ------ 5/6 [nbformat]\n",
      "   --------------------------------- ------ 5/6 [nbformat]\n",
      "   --------------------------------- ------ 5/6 [nbformat]\n",
      "   ---------------------------------------- 6/6 [nbformat]\n",
      "\n",
      "Successfully installed fastjsonschema-2.21.1 jsonschema-4.25.0 jsonschema-specifications-2025.4.1 nbformat-5.10.4 referencing-0.36.2 rpds-py-0.27.0\n"
     ]
    }
   ],
   "source": [
    "#Install all dependency packages for the course\n",
    "#Remember to execute this before running any of the exercises\n",
    "!pip install tenacity==9.0.0\n",
    "!pip install langchain==0.3.12\n",
    "!pip install langchain-openai==0.2.12\n",
    "!pip install langchain_community==0.3.12\n",
    "!pip install langgraph==0.2.59\n",
    "!pip install pysqlite3-binary==0.5.4\n",
    "!pip install langchain_chroma==0.1.4\n",
    "!pip install pandas==2.2.3\n",
    "!pip install pypdf==5.1.0\n",
    "!pip install nbformat==5.10.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921a9354-af14-4403-b89d-244f74534c91",
   "metadata": {},
   "source": [
    "## 2.3. Setup Function Tools for ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42b44c4e-f2d1-4aec-b14c-4653407345b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "#Tool annotation identifies a function as a tool automatically\n",
    "@tool\n",
    "def find_sum(x:int, y:int) -> int :\n",
    "    #The docstring comment describes the capabilities of the function\n",
    "    #It is used by the agent to discover the function's inputs, outputs and capabilities\n",
    "    \"\"\"\n",
    "    This function is used to add two numbers and return their sum.\n",
    "    It takes two integers as inputs and returns an integer as output.\n",
    "    \"\"\"\n",
    "    return x + y\n",
    "\n",
    "@tool\n",
    "def find_product(x:int, y:int) -> int :\n",
    "    \"\"\"\n",
    "    This function is used to multiply two numbers and return their product.\n",
    "    It takes two integers as inputs and returns an integer as ouput.\n",
    "    \"\"\"\n",
    "    return x * y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafd21f3-8566-494c-b12e-affed2f78cc9",
   "metadata": {},
   "source": [
    "## 2.4. Create a basic ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e019404-dc11-4e10-93cd-94ac6a9d2f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "#Setup the LLM for the agent\n",
    "\n",
    "#API info. Replace with your own keys and end points\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"]=\"4e4ab31800a64ae892cbb768fe28c0fc\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"]=\"https://agentic-ai-course-kumaran.openai.azure.com/\"\n",
    "\n",
    "#Setup the LLM\n",
    "model = AzureChatOpenAI(\n",
    "    azure_deployment=\"gpt-4o\" ,\n",
    "    api_version=\"2023-03-15-preview\",\n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "#Test the model\n",
    "#response = llm.invoke(\"Hello, how are you?\")\n",
    "#print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0922ce3f-5e29-459e-a86f-26c4022491e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import AIMessage,HumanMessage,SystemMessage\n",
    "\n",
    "#Create list of tools available to the agent\n",
    "agent_tools=[find_sum, find_product]\n",
    "\n",
    "#System prompt\n",
    "system_prompt = SystemMessage(\n",
    "    \"\"\"You are a Math genius who can solve math problems. Solve the\n",
    "    problems provided by the user, by using only tools available. \n",
    "    Do not solve the problem yourself\"\"\"\n",
    ")\n",
    "\n",
    "agent_graph=create_react_agent(\n",
    "    model=model, \n",
    "    state_modifier=system_prompt,\n",
    "    tools=agent_tools)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6e6363-55de-4e5b-b6c6-b77c6f5e6358",
   "metadata": {},
   "source": [
    "## 2.5. Execute the ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e000857-80ba-49fe-82d3-89993b63ebf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent returned : The sum of 2 and 3 is 5. \n",
      "\n",
      "Step by Step execution : \n",
      "================================ Human Message =================================\n",
      "\n",
      "what is the sum of 2 and 3 ?\n",
      "================================== Ai Message ==================================\n",
      "Tool Calls:\n",
      "  find_sum (call_G4DhTdCh4rKR4TAWkfVn7E0b)\n",
      " Call ID: call_G4DhTdCh4rKR4TAWkfVn7E0b\n",
      "  Args:\n",
      "    x: 2\n",
      "    y: 3\n",
      "================================= Tool Message =================================\n",
      "Name: find_sum\n",
      "\n",
      "5\n",
      "================================== Ai Message ==================================\n",
      "\n",
      "The sum of 2 and 3 is 5.\n"
     ]
    }
   ],
   "source": [
    "#Example 1\n",
    "inputs = {\"messages\":[(\"user\",\"what is the sum of 2 and 3 ?\")]}\n",
    "\n",
    "result = agent_graph.invoke(inputs)\n",
    "\n",
    "#Get the final answer\n",
    "print(f\"Agent returned : {result['messages'][-1].content} \\n\")\n",
    "\n",
    "print(\"Step by Step execution : \")\n",
    "for message in result['messages']:\n",
    "    print(message.pretty_repr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eda8502f-7ba9-44ba-a19c-5720871a3c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent returned : 3 multiplied by 2 is 6, and 5 + 1 is also 6. \n",
      "\n",
      "Step by Step execution : \n",
      "================================ Human Message =================================\n",
      "\n",
      "What is 3 multipled by 2 and 5 + 1 ?\n",
      "================================== Ai Message ==================================\n",
      "Tool Calls:\n",
      "  find_product (call_nlwakLV1BZaIgMUHBW7phBPj)\n",
      " Call ID: call_nlwakLV1BZaIgMUHBW7phBPj\n",
      "  Args:\n",
      "    x: 3\n",
      "    y: 2\n",
      "  find_sum (call_Pz14Bpqzsv63UdQK7znMElqO)\n",
      " Call ID: call_Pz14Bpqzsv63UdQK7znMElqO\n",
      "  Args:\n",
      "    x: 5\n",
      "    y: 1\n",
      "================================= Tool Message =================================\n",
      "Name: find_product\n",
      "\n",
      "6\n",
      "================================= Tool Message =================================\n",
      "Name: find_sum\n",
      "\n",
      "6\n",
      "================================== Ai Message ==================================\n",
      "\n",
      "3 multiplied by 2 is 6, and 5 + 1 is also 6.\n"
     ]
    }
   ],
   "source": [
    "#Example 2\n",
    "inputs = {\"messages\":[(\"user\",\"What is 3 multipled by 2 and 5 + 1 ?\")]}\n",
    "\n",
    "result = agent_graph.invoke(inputs)\n",
    "\n",
    "#Get the final answer\n",
    "print(f\"Agent returned : {result['messages'][-1].content} \\n\")\n",
    "\n",
    "print(\"Step by Step execution : \")\n",
    "for message in result['messages']:\n",
    "    print(message.pretty_repr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f610935-396f-487f-90c1-c44b7e394e07",
   "metadata": {},
   "source": [
    "## 2.6. Debugging the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9049e1d-8461-4b32-82b5-4539dfbf0b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[-1:checkpoint]\u001b[0m \u001b[1mState at the end of step -1:\n",
      "\u001b[0m{'messages': []}\n",
      "\u001b[36;1m\u001b[1;3m[0:tasks]\u001b[0m \u001b[1mStarting 1 task for step 0:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3m__start__\u001b[0m -> {'messages': [('user', 'what is the sum of 2 and 3 ?')]}\n",
      "\u001b[36;1m\u001b[1;3m[0:writes]\u001b[0m \u001b[1mFinished step 0 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [('user', 'what is the sum of 2 and 3 ?')]\n",
      "\u001b[36;1m\u001b[1;3m[0:checkpoint]\u001b[0m \u001b[1mState at the end of step 0:\n",
      "\u001b[0m{'messages': [HumanMessage(content='what is the sum of 2 and 3 ?', additional_kwargs={}, response_metadata={}, id='a4364fc8-0afc-4f46-971a-ea1acff7f3a1')]}\n",
      "\u001b[36;1m\u001b[1;3m[1:tasks]\u001b[0m \u001b[1mStarting 1 task for step 1:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3magent\u001b[0m -> {'is_last_step': False,\n",
      " 'messages': [HumanMessage(content='what is the sum of 2 and 3 ?', additional_kwargs={}, response_metadata={}, id='a4364fc8-0afc-4f46-971a-ea1acff7f3a1')],\n",
      " 'remaining_steps': 24}\n",
      "\u001b[36;1m\u001b[1;3m[1:writes]\u001b[0m \u001b[1mFinished step 1 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_sLAPT3bdzKiVm0Qy6jiQ86z6', 'function': {'arguments': '{\"x\":2,\"y\":3}', 'name': 'find_sum'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 159, 'total_tokens': 177, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_04751d0b65', 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-d90f1b42-6c38-4d8c-8e98-9e735d5ba144-0', tool_calls=[{'name': 'find_sum', 'args': {'x': 2, 'y': 3}, 'id': 'call_sLAPT3bdzKiVm0Qy6jiQ86z6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 159, 'output_tokens': 18, 'total_tokens': 177, 'input_token_details': {}, 'output_token_details': {}})]\n",
      "\u001b[36;1m\u001b[1;3m[1:checkpoint]\u001b[0m \u001b[1mState at the end of step 1:\n",
      "\u001b[0m{'messages': [HumanMessage(content='what is the sum of 2 and 3 ?', additional_kwargs={}, response_metadata={}, id='a4364fc8-0afc-4f46-971a-ea1acff7f3a1'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_sLAPT3bdzKiVm0Qy6jiQ86z6', 'function': {'arguments': '{\"x\":2,\"y\":3}', 'name': 'find_sum'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 159, 'total_tokens': 177, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_04751d0b65', 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-d90f1b42-6c38-4d8c-8e98-9e735d5ba144-0', tool_calls=[{'name': 'find_sum', 'args': {'x': 2, 'y': 3}, 'id': 'call_sLAPT3bdzKiVm0Qy6jiQ86z6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 159, 'output_tokens': 18, 'total_tokens': 177, 'input_token_details': {}, 'output_token_details': {}})]}\n",
      "\u001b[36;1m\u001b[1;3m[2:tasks]\u001b[0m \u001b[1mStarting 1 task for step 2:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mtools\u001b[0m -> {'is_last_step': False,\n",
      " 'messages': [HumanMessage(content='what is the sum of 2 and 3 ?', additional_kwargs={}, response_metadata={}, id='a4364fc8-0afc-4f46-971a-ea1acff7f3a1'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_sLAPT3bdzKiVm0Qy6jiQ86z6', 'function': {'arguments': '{\"x\":2,\"y\":3}', 'name': 'find_sum'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 159, 'total_tokens': 177, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_04751d0b65', 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-d90f1b42-6c38-4d8c-8e98-9e735d5ba144-0', tool_calls=[{'name': 'find_sum', 'args': {'x': 2, 'y': 3}, 'id': 'call_sLAPT3bdzKiVm0Qy6jiQ86z6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 159, 'output_tokens': 18, 'total_tokens': 177, 'input_token_details': {}, 'output_token_details': {}})],\n",
      " 'remaining_steps': 23}\n",
      "\u001b[36;1m\u001b[1;3m[2:writes]\u001b[0m \u001b[1mFinished step 2 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [ToolMessage(content='5', name='find_sum', tool_call_id='call_sLAPT3bdzKiVm0Qy6jiQ86z6')]\n",
      "\u001b[36;1m\u001b[1;3m[2:checkpoint]\u001b[0m \u001b[1mState at the end of step 2:\n",
      "\u001b[0m{'messages': [HumanMessage(content='what is the sum of 2 and 3 ?', additional_kwargs={}, response_metadata={}, id='a4364fc8-0afc-4f46-971a-ea1acff7f3a1'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_sLAPT3bdzKiVm0Qy6jiQ86z6', 'function': {'arguments': '{\"x\":2,\"y\":3}', 'name': 'find_sum'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 159, 'total_tokens': 177, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_04751d0b65', 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-d90f1b42-6c38-4d8c-8e98-9e735d5ba144-0', tool_calls=[{'name': 'find_sum', 'args': {'x': 2, 'y': 3}, 'id': 'call_sLAPT3bdzKiVm0Qy6jiQ86z6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 159, 'output_tokens': 18, 'total_tokens': 177, 'input_token_details': {}, 'output_token_details': {}}),\n",
      "              ToolMessage(content='5', name='find_sum', id='5c097231-1471-4a03-a864-54412526ce77', tool_call_id='call_sLAPT3bdzKiVm0Qy6jiQ86z6')]}\n",
      "\u001b[36;1m\u001b[1;3m[3:tasks]\u001b[0m \u001b[1mStarting 1 task for step 3:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3magent\u001b[0m -> {'is_last_step': False,\n",
      " 'messages': [HumanMessage(content='what is the sum of 2 and 3 ?', additional_kwargs={}, response_metadata={}, id='a4364fc8-0afc-4f46-971a-ea1acff7f3a1'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_sLAPT3bdzKiVm0Qy6jiQ86z6', 'function': {'arguments': '{\"x\":2,\"y\":3}', 'name': 'find_sum'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 159, 'total_tokens': 177, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_04751d0b65', 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-d90f1b42-6c38-4d8c-8e98-9e735d5ba144-0', tool_calls=[{'name': 'find_sum', 'args': {'x': 2, 'y': 3}, 'id': 'call_sLAPT3bdzKiVm0Qy6jiQ86z6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 159, 'output_tokens': 18, 'total_tokens': 177, 'input_token_details': {}, 'output_token_details': {}}),\n",
      "              ToolMessage(content='5', name='find_sum', id='5c097231-1471-4a03-a864-54412526ce77', tool_call_id='call_sLAPT3bdzKiVm0Qy6jiQ86z6')],\n",
      " 'remaining_steps': 22}\n",
      "\u001b[36;1m\u001b[1;3m[3:writes]\u001b[0m \u001b[1mFinished step 3 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [AIMessage(content='The sum of 2 and 3 is 5.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 186, 'total_tokens': 199, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_04751d0b65', 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='run-1331ed90-821c-4a2e-ac1e-8f76f5999208-0', usage_metadata={'input_tokens': 186, 'output_tokens': 13, 'total_tokens': 199, 'input_token_details': {}, 'output_token_details': {}})]\n",
      "\u001b[36;1m\u001b[1;3m[3:checkpoint]\u001b[0m \u001b[1mState at the end of step 3:\n",
      "\u001b[0m{'messages': [HumanMessage(content='what is the sum of 2 and 3 ?', additional_kwargs={}, response_metadata={}, id='a4364fc8-0afc-4f46-971a-ea1acff7f3a1'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_sLAPT3bdzKiVm0Qy6jiQ86z6', 'function': {'arguments': '{\"x\":2,\"y\":3}', 'name': 'find_sum'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 159, 'total_tokens': 177, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_04751d0b65', 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-d90f1b42-6c38-4d8c-8e98-9e735d5ba144-0', tool_calls=[{'name': 'find_sum', 'args': {'x': 2, 'y': 3}, 'id': 'call_sLAPT3bdzKiVm0Qy6jiQ86z6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 159, 'output_tokens': 18, 'total_tokens': 177, 'input_token_details': {}, 'output_token_details': {}}),\n",
      "              ToolMessage(content='5', name='find_sum', id='5c097231-1471-4a03-a864-54412526ce77', tool_call_id='call_sLAPT3bdzKiVm0Qy6jiQ86z6'),\n",
      "              AIMessage(content='The sum of 2 and 3 is 5.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 186, 'total_tokens': 199, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_04751d0b65', 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {}}, id='run-1331ed90-821c-4a2e-ac1e-8f76f5999208-0', usage_metadata={'input_tokens': 186, 'output_tokens': 13, 'total_tokens': 199, 'input_token_details': {}, 'output_token_details': {}})]}\n"
     ]
    }
   ],
   "source": [
    "agent_graph=create_react_agent(\n",
    "    model=model, \n",
    "    state_modifier=system_prompt,\n",
    "    tools=agent_tools,\n",
    "    debug=True)\n",
    "\n",
    "inputs = {\"messages\":[(\"user\",\"what is the sum of 2 and 3 ?\")]}\n",
    "\n",
    "result = agent_graph.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5523110-eb01-4c4d-a3fd-033e1d822c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
